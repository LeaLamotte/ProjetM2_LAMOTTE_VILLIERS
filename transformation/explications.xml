<?xml version="1.0" encoding="ISO-8859-1"?>
<?xml-stylesheet type="application/xml" href="explications.xsl"?>

<document>
<titre>Documents structurés - Exercices autour du langage XML</titre>

<!-- En-tête -->

<entete id="top">
  <titre_entete>Représentation XML -
  Projet sur l'analyse de corpus annotés</titre_entete>
  <presentation>Projet réalisé dans le cadre du cours XML au sein du master TAL de l'Inalco - M2S1 -
  Auteur : Léa Lamotte - Victorien Villiers</presentation>

  <!-- Barre de navigation -->
  
  <menu>
		
		<bouton>
			<titre_bouton anchor ="pres">Présentation</titre_bouton>
		</bouton>
		
		<bouton>
			<titre_bouton anchor ="corpus">Corpus</titre_bouton>
		</bouton>
		
		<bouton>
			<titre_bouton anchor ="script">Scripts</titre_bouton>
		</bouton>
			
		<bouton>
			<titre_bouton anchor ="tab">Tableau</titre_bouton>
		</bouton>
		
		<bouton>
			<titre_bouton anchor ="concl">Conclusion</titre_bouton>
		</bouton>
	
    </menu>
	
	<!-- Corps -->

</entete>
<corps>

	<!-- Présentation -->

	<exercice id="pres">
		<id>pres</id>
			<exercice_intro>
				<titre_paragraphe> Présentation du projet</titre_paragraphe>
				<paragraphe>L'objectif de ce projet est d'analyser les ressemblances et les divergences de plusieurs corpus annotés du français, notamment les écarts entre la langue orale et la langue écrite. Les corpus textuels sont des collections de documents variés, censés représenter la langue dans un contexte particulier. L'analyse de ces textes à l'aide d'annotations et d'un format structuré permet de mettre à jour leurs caractéristiques et ainsi de faire émerger, notamment à l'aide de visuels et de traitements variés (transformations XSL, requêtes Xquery), des similitudes ou, au contraire, des ruptures.</paragraphe>
			</exercice_intro>
			<exercice_corps>
				<elem>
					<titre_corps>Problématique : Écrit VS Oral</titre_corps>
					<paragraphe_corps>
						<text>
						La problématique de notre projet consistera à faire transparaître, à l'aide de vastes jeux de données, les divergence et ressemblances entre les textes oraux et écrits. Souvent moins traités dans l'analyse de corpus, l'oral va présenter des caractéristiques singulières qu'on ne retrouve généralement pas à l'écrit, c'est ce que nous tenterons de présenter. Enfin, on dénote également des éléments spécifiques aux textes écrits, nous verrons comment ils se manifestent dans le corpus, en comparaison des textes oraux.
						</text>
					</paragraphe_corps>
				</elem>
				<elem>
					<paragraphe_corps><answer> Particularités des jeux de données textuelles...</answer></paragraphe_corps>
					<paragraphe_corps>
						<text>
						Contrairement à des jeux de données « classiques » comportant des données numériques (statistiques, informations géospatiales), les données textuelles n'offrent pas d'informations a priori. Une annotation sous forme de métadonnées et un prétraitement des textes sont donc nécessaires pour pouvoir effectuer une analyse plus fine des données.
						</text>
					</paragraphe_corps>
				</elem>
				<elem>
					<titre_corps>Étapes du projet</titre_corps>
					<paragraphe_corps>
						<text>
						Notre projet se divise en plusieurs étapes. Tout d'abord, nous passons par une phase de prétraitement des fichiers contenant les corpus annotés, afin de créer une structure de données au format XML, destinées à l'analyse et à l'évaluation. Nous utilisons, pour ce faire, plusieurs scripts en Python. Le format XML offre de nombreux avantage, notamment grâce aux langages de requêtes permettant de tirer partie des métadonnées et de la structure des données pour pouvoir effectuer des opérations de traitement sur l'ensemble d'un corpus. Cette structure permet également d'obtenir un contenu uniforme, facile à parcourir et à étudier. Une fois les corpus bruts prétraités, la deuxième tâche consiste à analyser les fichiers structurés obtenus grâce à un ensemble de requêtes et de traitements afin d'effectuer des comparaisons et diverses visualisations. Enfin, nous stockons les visuels obtenus dans un tableau, afin d'accéder facilement au résultats des traitements finaux. La présente page de présentation et la page contenant le tableau sont également réalisées à partir de fichiers XML.
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<text>
						Schéma du processus de transformation
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<image url="./images/process.png">
						</image>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<return>
						Retour au menu
						</return>
					</paragraphe_corps>
				</elem>
				
			</exercice_corps>
	</exercice>
	
	<!-- Corpus -->
	
	<exercice id="corpus">
		<id>corpus</id>
			<exercice_intro>
				<titre_paragraphe> Corpus</titre_paragraphe>
				<paragraphe>Pour notre projet, nous sommes parti de l'analyse de deux corpus principaux, un premier regroupant exclusivement des extraits de langue orale (corpus Rhapsodie), et un second composé intégralement de documents écrits (corpus Sequoia). </paragraphe>
				<paragraphe>--------------</paragraphe>
			</exercice_intro>
			
			<exercice_corps>
				<elem>
					<titre_corps>Corpus Sequoia</titre_corps>
					<paragraphe_corps>
						<text>--------------</text>
						<liste_ul>
							<elem_liste><compound-content><bold-content>Nom : </bold-content><text-content>Deep Sequoia corpus</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Source : </bold-content><lien-content url="https://deep-sequoia.inria.fr/fr/">https://deep-sequoia.inria.fr/fr/</lien-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Taille (octets) : </bold-content><text-content>11,2 Mo</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Échantillonnage et genre : </bold-content><text-content> corpus de langue française annoté, intégrant des informations sur les dépendances syntaxiques de surface et profonde des mots, ainsi que leurs catégories grammaticales (arbres syntaxiques ou treebank) au format UD (CoNLL-u)</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Modalité : </bold-content><text-content>écrit, documents provenant d'Europarl, du corpus l'Est Republicain, des pages Wikipédia de la communauté France, et de l'agence européenne du médicament.</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Taille : </bold-content><text-content>environ 3200 phrases </text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Annotations et outils : </bold-content><text-content>annotation manuelle des catégories morpho-syntaxiques et de la structure syntagmatique en suivant les consignes d'annotation du French Treebank ; convention de transcription du corpus : </text-content><lien-content url="https://deep-sequoia.inria.fr/deep-sequoia-guide.pdf">https://deep-sequoia.inria.fr/deep-sequoia-guide.pdf</lien-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Documentation : </bold-content><text-content>corpus issu des travaux réalisés par les équipes de l'INRIA, du LLF, du LORIA et du LabEx EFL. Articles de référence :</text-content></compound-content></elem_liste>
							<elem_liste><text-content>Marie Candito, Guy Perrier, Bruno Guillaume, Corentin Ribeyre, Karën Fort, Djamé Seddah and Éric de la Clergerie. (2014) Deep Syntax Annotation of the Sequoia French Treebank. Proc. of LREC 2014, Reykjavic, Iceland.</text-content></elem_liste>
							<elem_liste><text-content>Guy Perrier, Marie Candito, Bruno Guillaume, Corentin Ribeyre, Karën Fort and Djamé Seddah. (2014) Un schéma d'annotation en dépendances syntaxiques profondes pour le français. Proc. of TALN 2014, Marseille, France.</text-content></elem_liste>
							<elem_liste><text-content>Marie Candito and Djamé Seddah. (2012) Le corpus Sequoia : annotation syntaxique et exploitation pour l'adaptation d'analyseur par pont lexical, Proceedings of TALN'2012, Grenoble, France</text-content></elem_liste>
							<elem_liste><compound-content><bold-content>Licence et droit d'utilisation : </bold-content><text-content>Licence LGPL-LR (Lesser General Public License For Linguistic Resources). Mention de l'article : Candito M. and Seddah D., 2012 : "Le corpus Sequoia : annotation syntaxique et exploitation pour l'adaptation d'analyseur par pont lexical", Actes de TALN'2012, Grenoble, France</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Extrait : "cette exposition nous apprend [...]" </bold-content><ml-code-content>
							<ml-code-content-line>1	Cette	ce	D	DET	g=f|n=s|s=dem	2	det	_	_</ml-code-content-line>
							<ml-code-content-line>2	exposition	exposition	N	NC	g=f|n=s|s=c	4	suj:suj	_	_</ml-code-content-line>
							<ml-code-content-line>3	nous	le	CL	CLO	n=p|p=1|s=obj	4	a_obj:a_obj	_	_</ml-code-content-line>
							<ml-code-content-line>4	apprend	apprendre	V	V	dl=apprendre|dm=ind|m=ind|n=s|p=3|t=pst	0	root	_	_</ml-code-content-line>
							</ml-code-content></compound-content></elem_liste>
						</liste_ul>
						
						<button url="..\data\sequoia-8.2\sequoia.deep_and_surf.conll">
						Corpus d'origine complet
						</button>
						
						<button url="..\xml\Sequoia.xml">
						Corpus XML après traitement
						</button>
						
					</paragraphe_corps>
				</elem>
			</exercice_corps>
			
			<exercice_corps>
				<elem>
					<titre_corps>Corpus Rhapsodie</titre_corps>
					<paragraphe_corps>
						<text>--------------</text>
						<liste_ul>
							<elem_liste><compound-content><bold-content>Nom : </bold-content><text-content>Corpus Rhapsodie, version annotée en microsyntaxe</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Source : </bold-content><lien-content url="https://www.projet-rhapsodie.fr/">https://www.projet-rhapsodie.fr/</lien-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Taille (octets) : </bold-content><text-content>3,8 Mo</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Échantillonnage et genre : </bold-content><text-content>corpus de français parlé annoté pour la prosodie et la syntaxe, intégrant des informations sur les rections, dépendances (arbres syntaxiques ou treebank) et catégories grammaticales  au format tabulaire</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Modalité : </bold-content><text-content>oral, échantillon de 30 heures de parole, regroupant des transcriptions d'interview, de parole libre, de commentaires sportifs, etc. issus d'une compilation de corpus externes et internes au projet</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Taille : </bold-content><text-content>retranscription de 30h de parole</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Annotations et outils : </bold-content><text-content>annotation manuelle des dépendances syntaxiques sur 6h de parole à l'aide du logiciel d'édition Arbil (format IMDI), guide d'annotation utilisé : </text-content><lien-content url="www.projet-rhapsodie.fr/wp-content/uploads/2017/04/Protocole-de-codage-microsyntaxique-2013-10-1.pdf">www.projet-rhapsodie.fr/wp-content/uploads/2017/04/Protocole-de-codage-microsyntaxique-2013-10-1.pdf</lien-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Documentation : </bold-content><text-content>corpus annoté issus des travaux réalisés par les équipes de MODYCO, de l'IRCAM, du LATTICE, de l'ERSS et du LPL. Lien vers les publications : https://www.projet-rhapsodie.fr/bibliographie/</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Licence et droit d'utilisation : </bold-content><text-content>Licence Creative Commons Attribution, citation des sources des corpus dans le respect des propriétés intellectuelles selon qu'il s'agisse de corpus externe ou interne</text-content></compound-content></elem_liste>
							<elem_liste><compound-content><bold-content>Extrait : "est-ce [...]" </bold-content><ml-code-content>
							<ml-code-content-line>D0001	1	1	est	$L1	B	est	être	V	indicative	present	3	sg		0	root	0	root									O	B	B	O	O	O	O	O	O	O	O	O	O	O	B	mml2	B	lone-dis-strong	hmm2	B	dis-strong	hmm2	B	dis-strong	hmm2	B	Hh	0	0			2.2265	2.2665	189.99999999999994	114.99999999999999	97.16526451681739	95.04111744094945</ml-code-content-line>
							<ml-code-content-line>D0001	1	2	-	$L1	B	-ce	ce	Cl			3	sg	masc	1	sub	1	sub									O	I	I	O	O	O	O	O	O	O	O	O	O	O	I	mml2	I	lone-dis-strong	hmm2	I	dis-strong	hmm2	I	dis-strong	hmm2	I	Hh	0	0			2.2665	2.4165	189.99999999999994	114.99999999999999	97.16526451681739	95.04111744094945</ml-code-content-line>
							</ml-code-content></compound-content></elem_liste>
						</liste_ul>
						
						<button url="..\data\Rhapsodie\Rhap-D0001.micro_macro_prosody.tabular">
						Fichier du corpus d'origine
						</button>
						
						<button url="..\xml\Rhapsodie.xml">
						Corpus XML après traitement
						</button>
						
					</paragraphe_corps>
				</elem>
			</exercice_corps>
			
			<exercice_corps>
					
				<elem>
					<paragraphe_corps><answer> Questions d'harmonisation...</answer></paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<text>Afin de pouvoir comparer les deux corpus principaux sur un pied d'égalité, nous avons, au moment du traitement, décidé d'harmoniser l'étiquetage utilisé dans les sorties XML. Par souci de simplicité, nous avons conservé l'étiquetage du corpus Sequoia. Nous avons également dû faire quelques ajustement, notamment la fusion d'étiquettes comme les conjonctions (en bleu dans le tableau récapitulatif). Nous avons également regroupé certaines étiquettes n'apparaissant pas dans l'un ou l'autre des corpus. C'est notamment le cas des étiquettes « emprunt », « ponctuation » et « préfixe », présentes dans le corpus Sequoia, mais absente du corpus Rhapsodie, et des étiquettes « inconnu » et « interrogatifs/relatifs » qui, à l'inverse, étaient présentes dans le corpus Rhapsodie mais inutilisée dans le corpus écrit Sequoia (en rouge dans le tableau récapitulatif).</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<text>
						Tableau récapitulatif : harmonisation des catégories grammaticales
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<tableau>
							<ligne><data-h>Rhapsodie</data-h><data-h>Sequoia</data-h><data-h>Signification</data-h></ligne>
							<ligne><data>Adj</data><data>A</data><data>adjectif</data></ligne>
							<ligne><data>Adv</data><data>ADV</data><data>adverbe</data></ligne>
							<ligne><data-k>CS</data-k><data-k>C</data-k><data-k>conjonction</data-k></ligne>
							<ligne><data-k>J</data-k><data-k>---</data-k><data-k>conjonction</data-k></ligne>
							<ligne><data>Cl</data><data>CL</data><data>clitique</data></ligne>
							<ligne><data>D</data><data>D</data><data>déterminant</data></ligne>
							<ligne><data-o>---</data-o><data-o>ET</data-o><data-o>emprunt</data-o></ligne>
							<ligne><data>I</data><data>I</data><data>interjection</data></ligne>
							<ligne><data>N</data><data>N</data><data>nom</data></ligne>
							<ligne><data>Pre</data><data>P</data><data>préposition</data></ligne>
							<ligne><data>Pre+D</data><data>P+D</data><data>prép.+dét.</data></ligne>
							<ligne><data>Pre+Qu</data><data>P+PRO</data><data>auquel/lequel</data></ligne>
							<ligne><data-o>---</data-o><data-o>PONCT</data-o><data-o>ponctuation</data-o></ligne>
							<ligne><data-o>---</data-o><data-o>PREF</data-o><data-o>préfixe</data-o></ligne>
							<ligne><data>Pro</data><data>PRO</data><data>pronom</data></ligne>
							<ligne><data>V</data><data>V</data><data>verbe</data></ligne>
							<ligne><data-o>X</data-o><data-o>---</data-o><data-o>inconnu</data-o></ligne>
							<ligne><data-o>Qu</data-o><data-o>---</data-o><data-o>interrogatifs/relatifs</data-o></ligne>
						</tableau>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<return>
						Retour au menu
						</return>
					</paragraphe_corps>
				</elem>
								
			</exercice_corps>
			
	</exercice>
	
	<!-- Scripts -->
	
	<exercice id="script">
		<id>script</id>
			<exercice_intro>
				<titre_paragraphe> Scripts</titre_paragraphe>
				<paragraphe>Pour passer la première étape de transformation des fichiers bruts en fichiers XML, nous avons eu recours à des scripts de conversion en Python. Le but de ces scripts est de traiter les données au format tabulaire des corpus annotés, afin de produire des fichiers harmonisés et exploitables. Compte tenu des différences de format des deux corpus principaux, nous avons dû créer deux scripts distincts. </paragraphe>
			</exercice_intro>
			<exercice_corps>
				
				<elem>
					<paragraphe_corps>
						<text>
						Les deux corpus utilisant une structure de type treebank, nous avons choisi de partir sur une représentation en arbres syntaxiques, correspondant chacun aux phrases et syntagmes des documents du corpus. Chaque arbre syntaxique est lui-même composé de tokens que nous avons balisé comme tel dans le fichier XML. Les catégories grammaticales (ou POS, "Part of Speech") ont quant à elles été représentées à l'aide de paramètres au sein des balises. Nous avons également ajouté un niveau hiérarchique supplémentaire « mot », étant donné qu'un même mot peut être composé de plusieurs tokens, selon les règles d'annotation du corpus Rhapsodie.
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<text>
						La première partie du script consiste à analyser la structure des données de départ, afin de pouvoir les lire et les récupérer. Une fois le fichier parcouru et les données analysées, la deuxième étape consiste à créer un fichier de sortie pour les stocker respectant une grammaire XML donnée. Nous avons décidé, afin de conserver un format homogène, d'utiliser une grammaire unifiée pour les deux fichiers XML en sortie au format DTD. Les scripts créés ne nécessitent pas d'installation de bibliothèques particulières et peuvent être utilisés directement sur les corpus bruts.
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<titre_corps>Lien vers les scripts</titre_corps>
					<paragraphe_corps>
						<button url="../script/Sequoia2XML.py">
						Script Sequoia > XML
						</button>
						<button url="../script/Rhapsodie2XML.py">
						Script Rhapsodie > XML
						</button>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<return>
						Retour au menu
						</return>
					</paragraphe_corps>
				</elem>
				
			</exercice_corps>
	</exercice>
	
	<!-- Tableau -->
	
	<exercice id="tab">
		<id>tab</id>
			<exercice_intro>
				<titre_paragraphe> Tableau</titre_paragraphe>
				<paragraphe>Après avoir balisé et converti les données des fichiers, nous avons effectué plusieurs requêtes sur les fichiers XML produits, afin de comparer le résultat des deux corpus. Nous résumons les résultats analyses sous formes de tables et autres visualisations au sein d'un même tableau. Nous avons notamment cherché à mettre à jour les principales différences entre les deux corpus, telles que les catégories grammaticales majoritaires, ou encore certaines caractéristiques spécifiques, telles que la surabondance de clitiques ou de déictiques, ou encore la richesse du vocabulaire.</paragraphe>
			</exercice_intro>
			<exercice_corps>			
				<elem>
					<paragraphe_corps>
						<button url="./tableau.html">
						Tableau
						</button>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<return>
						Retour au menu
						</return>
					</paragraphe_corps>
				</elem>
				
			</exercice_corps>
	</exercice>
	
	<!-- Conclusion -->
	
	<exercice id="concl">
		<id>concl</id>
			<exercice_intro>
				<titre_paragraphe> Résultats d'analyse</titre_paragraphe>
				<paragraphe>Nous présentons ci-après plusieurs résultats de nos analyses après conversion et affichage des données au format XML. La problématique que nous avions soulevée était celle des différences entre deux corpus, l'un issu d'enregistrements oraux, l'autre d'une compilation de textes écrits. Nous avons tenté lors de la phase de consitution des fichiers structurés et de requêtes, d'orienter nos traitements afin de faire ressortir principalement certaines annotations comme les parties du discours, ou encore certains aspects comme la hiérachisaiton sous forme d'arbres, afin de bénéficier de points de comparaison.</paragraphe>
			</exercice_intro>
			<exercice_corps>				
				<elem>
					<paragraphe_corps><answer> Plusieurs différences...</answer></paragraphe_corps>
				</elem>
				
				<elem>
					<titre_corps>Spontanéité et parties du discours</titre_corps>
					<paragraphe_corps>
						<text>
						Avant toute chose, il est important de garder en tête que le corpus Rhapsodie est significativement plus petit que le corpus Sequoia.
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<image url="./xquery/Comparaison_taille_corpus.png">
						</image>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<text>
						Nous avons donc eu recours aux pourcentages pour évaluer la distribution des POS dans chaque type de discours et nous avons obtenus les résultats suivants:
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<image url="./xquery/Repartition_POS.png">
						</image>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<text>
						Comme on peut le constater à l'oeil nu, l'écrit contient une proportions de noms beaucoup plus importante que l'oral, et ce à quantité de pronoms comparable. Ce résultat est d'autant plus significatif que Sequoia ne considère pas les emprunts comme des parties du discours classiques, ce qui fait exploser la proportion des "Autres" qu'il contient.
						En contre-partie, l'oral contient d'avantage de verbes et d'interjections. 
						Le nombre de déterminant est sensiblement identique, alors que l'on aurait pu penser qu'à l'oral, leur usage en temps que phatiques lors des reformulations en décuplerait le nombre.
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<titre_corps>Complexité de la langue</titre_corps>
					<paragraphe_corps>
						<text>
						On constate grâce aux données révélées dans les fichiers XML que le corpus oral présente des phrases plus courtes mais un vocabulaire globalement aussi riche. Cependant cette diversité est probablement un artefact dû à la multitude de sujet abordés par les 57 sous-corpus de Rhapsodie.
						</text>
					</paragraphe_corps>
				</elem>
						
				<elem>
					<paragraphe_corps>
						<tableau>
							<ligne><data-h>Fichier</data-h><data-h>Rhapsodie</data-h><data-h>Sequoia</data-h></ligne>
							<ligne><data-k>Longueur moyenne d'un arbre</data-k><data-k>12.34</data-k><data-k>22.2</data-k></ligne>
							<ligne><data>Nombre de Tokens</data><data>35725</data><data>68802</data></ligne>
							<ligne><data>Nombre de Types</data><data>4567</data><data>10036</data></ligne>
							<ligne><data-o>Ratio (%)</data-o><data-o>12.78</data-o><data-o>14.59</data-o></ligne>
						</tableau>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<titre_corps>Particularités grammaticales</titre_corps>
					<paragraphe_corps>
						<text>
						Enfin, on constate après transformation des fichiers XML à l'aide de requêtes Xquery que le corpus oral omet régulièrement certaines formes comme la première moitié de double négation et présente des formes inédites comme les phatiques présentés ci-dessous. Nous n'avons pas étudier l'apocope (ex : j'veux) car nos deux corpus opèrent un traitement différent des apostrophes (comme en témoigne l'exemple en rouge).
						</text>
					</paragraphe_corps>
				</elem>
						
				<elem>
					<paragraphe_corps>
						<tableau>
							<ligne><data-h>Mot</data-h><data-h>Rhapsodie</data-h><data-h>Sequoia</data-h></ligne>
							<ligne><data-k>ne</data-k><data-k>99</data-k><data-k>193</data-k></ligne>
							<ligne><data-k>pas</data-k><data-k>379</data-k><data-k>283</data-k></ligne>
							<ligne><data>bah</data><data>16</data><data>0</data></ligne>
							<ligne><data>euh</data><data>1014</data><data>0</data></ligne>
							<ligne><data>eh</data><data>32</data><data>0</data></ligne>
							<ligne><data>ben</data><data>68</data><data>0</data></ligne>
							<ligne><data>mh</data><data>214</data><data>0</data></ligne>
							<ligne><data-o>jusqu</data-o><data-o>40</data-o><data-o>0</data-o></ligne>
						</tableau>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<text>
						De plus, la transcription de Rhapsodie ayant été effectuée par énormément de personnes différentes à des époques différentes selon des guides différents (harmonisés par la suite), nous ne pouvons pas garantir que les résultats auraient été pertinents.
						</text>
					</paragraphe_corps>
				</elem>
				
				<elem>
					<paragraphe_corps>
						<button url="./tableau.html">
						Tableau
						</button>
					</paragraphe_corps>
				</elem>

				<elem>
					<paragraphe_corps>
						<return>
						Retour au menu
						</return>
					</paragraphe_corps>
				</elem>
				
			</exercice_corps>
	</exercice>

</corps>
</document>
